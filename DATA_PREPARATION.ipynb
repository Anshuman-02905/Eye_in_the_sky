{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DATA_PREPARATION.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOy+GeDmjrCWbeNAf0Kj6j6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anshuman-02905/URBAN_MONITORING_SYSTEM/blob/main/DATA_PREPARATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from patchify import patchify\n",
        "from PIL import Image\n",
        "\n",
        "import random"
      ],
      "metadata": {
        "id": "ioOgUnIOP14m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image=\"D:/PROJECT/DATAPREPARATION/DATASET/Sentinel_png/\"\n",
        "annotation=\"D:/PROJECT/DATAPREPARATION/DATASET/Mask_png/\"\n",
        "final_image=\"D:/PROJECT/DATAPREPARATION/DATASET/256_patches/images/\"\n",
        "final_mask=\"D:/PROJECT/DATAPREPARATION/DATASET/256_patches/masks/\"\n",
        "root=\"D:/PROJECT/DATAPREPARATION/DATASET/\"\n",
        "images_prepped_train=\"D:/PROJECT/DATAPREPARATION/DATASET/256_patches/DATA/images_prepped_train/\"\n",
        "images_prepped_test=\"D:/PROJECT/DATAPREPARATION/DATASET/256_patches/DATA/images_prepped_test/\"\n",
        "annotations_prepped_train=\"D:/PROJECT/DATAPREPARATION/DATASET/256_patches/DATA/annotations_prepped_train/\"\n",
        "annotations_prepped_test=\"D:/PROJECT/DATAPREPARATION/DATASET/256_patches/DATA/annotations_prepped_test/\"\n",
        "#print(os.path.exists(images_prepped_train))"
      ],
      "metadata": {
        "id": "LsCTuQXMQDI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DU4KPbShPnLd"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sat Mar 12 13:25:47 2022\n",
        "\n",
        "@author: TILAK MONDAL\n",
        "\"\"\"\n",
        "\n",
        "#root_directory='C:\\Users\\TILAK MONDAL\\Desktop\\DATASET'\n",
        "#root_directory=\"C:\\Users\\TILAK MONDAL\\Desktop\\DATASET\\\"\n",
        "\n",
        "\n",
        "patch_size = 256\n",
        "c=0\n",
        "for path, subdirs, files in os.walk(image):\n",
        "    print(path)  \n",
        "    dirname = path.split(os.path.sep)[-1]\n",
        "    print(dirname)\n",
        "    images = os.listdir(path)  #List of all image names in this subdirectory\n",
        "    print(images)\n",
        "    for i, image_name in enumerate(images):  \n",
        "        if image_name.endswith(\".png\"):\n",
        "            #print(image_name)\n",
        "            image = cv2.imread(path+\"/\"+image_name, 1)  #Read each image as BGR\n",
        "            SIZE_X = (image.shape[1]//patch_size)*patch_size #Nearest size divisible by our patch size\n",
        "            SIZE_Y = (image.shape[0]//patch_size)*patch_size #Nearest size divisible by our patch size\n",
        "            image = Image.fromarray(image)\n",
        "            image = image.crop((0 ,0, SIZE_X, SIZE_Y))  #Crop from top left corner\n",
        "            #image = image.resize((SIZE_X, SIZE_Y))  #Try not to resize for semantic segmentation\n",
        "            image = np.array(image)   \n",
        "            print(\"Now patchifying image:\", path+\"/\"+image_name)\n",
        "            patches_img = patchify(image, (256, 256, 3), step=256)  #Step=256 for 256 patches means no over\n",
        "            \n",
        "            for i in range(patches_img.shape[0]):\n",
        "                for j in range(patches_img.shape[1]):\n",
        "                    \n",
        "                    single_patch_img = patches_img[i,j,:,:]\n",
        "                    #single_patch_img = (single_patch_img.astype('float32')) / 255. #We will preprocess using one of the backbones\n",
        "                    single_patch_img = single_patch_img[0] #Drop the extra unecessary dimension that patchify adds.                               \n",
        "                    \n",
        "                    cv2.imwrite(root+\"256_patches/images/\"+str(c)+\".png\", single_patch_img)\n",
        "                    c+=1\n",
        "                    #image_dataset.append(single_patch_img)\n",
        "c=0\n",
        "for path, subdirs, files in os.walk(annotation):\n",
        "    #print(path)  \n",
        "    dirname = path.split(os.path.sep)[-1]\n",
        "    print(dirname)\n",
        "    masks = os.listdir(path)  #List of all image names in this subdirectory\n",
        "    for i, mask_name in enumerate(masks):  \n",
        "        if mask_name.endswith(\".png\"):           \n",
        "            mask = cv2.imread(path+\"/\"+mask_name, 0)  #Read each image as Grey (or color but remember to map each color to an integer)\n",
        "            SIZE_X = (mask.shape[1]//patch_size)*patch_size #Nearest size divisible by our patch size\n",
        "            SIZE_Y = (mask.shape[0]//patch_size)*patch_size #Nearest size divisible by our patch size\n",
        "            mask = Image.fromarray(mask)\n",
        "            mask = mask.crop((0 ,0, SIZE_X, SIZE_Y))  #Crop from top left corner\n",
        "            #mask = mask.resize((SIZE_X, SIZE_Y))  #Try not to resize for semantic segmentation\n",
        "            mask = np.array(mask)             \n",
        "   \n",
        "            #Extract patches from each image\n",
        "            print(\"Now patchifying mask:\", path+\"/\"+mask_name)\n",
        "            patches_mask = patchify(mask, (256, 256), step=256)  #Step=256 for 256 patches means no overlap\n",
        "    \n",
        "            for i in range(patches_mask.shape[0]):\n",
        "                for j in range(patches_mask.shape[1]):\n",
        "                    \n",
        "                    single_patch_mask = patches_mask[i,j,:,:]\n",
        "                    #single_patch_img = (single_patch_img.astype('float32')) / 255. #No need to scale masks, but you can do it if you want\n",
        "                    #single_patch_mask = single_patch_mask[0] #Drop the extra unecessary dimension that patchify adds.                               \n",
        "                    cv2.imwrite(root+\"256_patches/masks/\"+str(c)+\".png\", single_patch_mask)\n",
        "                    c+=1\n",
        "                    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_dir = root+\"256_patches/images/\"\n",
        "train_mask_dir = root+\"256_patches/masks/\"\n",
        "\n",
        "img_list = os.listdir(train_img_dir)\n",
        "msk_list = os.listdir(train_mask_dir)\n",
        "\n",
        "num_images = len(os.listdir(train_img_dir))\n",
        "\n",
        "\n",
        "img_num = random.randint(0, num_images-1)\n",
        "\n",
        "img_for_plot = cv2.imread(train_img_dir+img_list[img_num], 1)\n",
        "img_for_plot = cv2.cvtColor(img_for_plot, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "mask_for_plot =cv2.imread(train_mask_dir+msk_list[img_num], 0)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(121)\n",
        "plt.imshow(img_for_plot)\n",
        "plt.title('Image')\n",
        "plt.subplot(122)\n",
        "plt.imshow(mask_for_plot, cmap='gray')\n",
        "plt.title('Mask')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BaPcAIoIP6Qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(os.path.exists(image+str(14)+\".png\"))\n",
        "def test_train_split(length,ratio,sed=0):\n",
        "  random.seed(sed)\n",
        "  st = list(range(0,length))\n",
        "  random.shuffle(st)\n",
        "  brk=int(ratio*length)\n",
        "  train=st[0:brk]\n",
        "  test=st[brk:length]\n",
        "  \n",
        "  for i in tqdm(train):\n",
        "    src_image_tr=final_image+str(i)+\".png\"\n",
        "    src_annote_tr=final_mask+str(i)+\".png\"\n",
        "    dst_image_tr=images_prepped_train+str(i)+\".png\"\n",
        "    dst_annote_tr=annotations_prepped_train+str(i)+\".png\"\n",
        "    \n",
        "    shutil.copyfile(src_image_tr,dst_image_tr)\n",
        "    shutil.copyfile(src_annote_tr,dst_annote_tr)\n",
        "  for i in tqdm(test):\n",
        "    src_image=final_image+str(i)+\".png\"\n",
        "    src_annote=final_mask+str(i)+\".png\"\n",
        "    dst_image=images_prepped_test+str(i)+\".png\"\n",
        "    dst_annote=annotations_prepped_test+str(i)+\".png\"\n",
        "    shutil.copyfile(src_image,dst_image)\n",
        "    shutil.copyfile(src_annote,dst_annote)\n",
        "\n",
        "\n",
        "  return test,train\n"
      ],
      "metadata": {
        "id": "HPhXNUYJPxV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test,train=test_train_split(num_images,0.75)"
      ],
      "metadata": {
        "id": "Ol5vC6yDPyvu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}